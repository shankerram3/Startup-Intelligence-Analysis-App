# Optimized Dockerfile for API deployment (without Playwright)
# This reduces memory usage significantly by excluding browser dependencies

# Stage 1: Build frontend
FROM node:20-alpine AS frontend-builder

WORKDIR /app/frontend

# Copy frontend package files
COPY frontend/package*.json ./

# Install frontend dependencies
RUN npm ci

# Copy frontend source
COPY frontend/ ./

# Build frontend for production
RUN npm run build

# Stage 2: Python backend with frontend (optimized for API)
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install minimal system dependencies (no Playwright deps)
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy optimized requirements (without Playwright)
COPY requirements-api.txt ./requirements.txt

# Install Python dependencies (without Playwright)
# This saves ~500MB+ memory since Playwright browsers aren't needed for API
RUN pip install --no-cache-dir -r requirements.txt

# Playwright is only needed for pipeline scraping, not API queries
# The API only queries the graph database, it doesn't scrape websites

# Copy application code
COPY . .

# Copy built frontend from builder stage
COPY --from=frontend-builder /app/frontend/dist ./frontend/dist

# Create directories for data
RUN mkdir -p data/articles data/metadata data/processing data/raw_data logs

# Expose API port
EXPOSE 8000

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV API_HOST=0.0.0.0
ENV API_PORT=8000
# Render uses PORT env var, but we support both PORT and API_PORT
ENV PORT=8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run the API server
CMD ["python", "api.py"]

